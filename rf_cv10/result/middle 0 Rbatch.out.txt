During startup - Warning message:
Setting LC_CTYPE failed, using "C" 
> library(tidyr)
> library(dplyr)

Attaching package: 'dplyr'

The following objects are masked from 'package:stats':

    filter, lag

The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union

> library(missForest)
> library(doParallel)
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
> library(randomForest)
randomForest 4.7-1.1
Type rfNews() to see new features/changes/bug fixes.

Attaching package: 'randomForest'

The following object is masked from 'package:dplyr':

    combine

> library('fastDummies')
> library(neuralnet)

Attaching package: 'neuralnet'

The following object is masked from 'package:dplyr':

    compute

> library(keras)
> load("../../data/temp/remData.Rdata")
> 
> r2_calc <- function(classifications, predictions){
+   
+   idx <- !is.na(predictions) & !is.na(classifications)
+   classifications <- classifications[idx]
+   predictions <- predictions[idx]
+   
+   1 - (sum((classifications-predictions)^2)/sum((classifications-mean(classifications))^2))
+   
+ }
> 
> print_dot_callback <- callback_lambda(
+   on_epoch_end = function(epoch, logs) {
+     if (epoch %% 80 == 0) cat("\n")
+     cat(".")
+   }
+ )  
2022-11-17 14:18:34.216721: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-17 14:18:38.603579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/sw/pkgs/coe/o/image-libraries/220318/lib:/sw/pkgs/arc/gcc/10.3.0/lib64:/opt/slurm/lib64::
2022-11-17 14:18:38.603603: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-11-17 14:18:38.966349: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-17 14:18:48.797237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/sw/pkgs/coe/o/image-libraries/220318/lib:/sw/pkgs/arc/gcc/10.3.0/lib64:/opt/slurm/lib64::
2022-11-17 14:18:48.798658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/sw/pkgs/coe/o/image-libraries/220318/lib:/sw/pkgs/arc/gcc/10.3.0/lib64:/opt/slurm/lib64::
2022-11-17 14:18:48.798668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Loaded Tensorflow version 2.10.1
> 
> df = taksRem %>% select(-contains("_na"))
> 
> df2 = inner_join(df, grdXwalk, by = 'CAMPUS')
> df2 = subset(df2,select = -c(COUNTY,GRDSPAN))
> check = df2 %>% pivot_longer(cols = -c(CAMPUS,GRDTYPE), names_to = c("type","variable"),names_pattern = "(.+)([A-Z]\\d{2})",values_to = "value")
> 
> check = check %>% pivot_wider(names_from = type,values_from = value)
> 
> check2 = check %>% mutate(out = case_when(GRDTYPE %in% c("S", "B") & !is.na(outh) ~ outh,
+                                           GRDTYPE %in% c("M", "E") ~ outm,
+                                           GRDTYPE %in% c("S", "B") & is.na(outh) ~ outm))
> 
> tf = covsRem_noscale %>% select(CAMPUS,matches("_34$"))
> ff = covsRem_noscale %>% select(CAMPUS,matches("_45$"))
> fs = covsRem_noscale %>% select(CAMPUS,matches("_56$"))
> ss = covsRem_noscale %>% select(CAMPUS,matches("_67$"))
> se = covsRem_noscale %>% select(CAMPUS,matches("_78$"))
> 
> name_34 = tf[c(which(rowSums(is.na(tf)) == ncol(tf)-1)),1] # campus name whose column entries are all na == campus not existent in 34
> name_45 = ff[c(which(rowSums(is.na(ff)) == ncol(ff)-1)),1]
> name_56 = fs[c(which(rowSums(is.na(fs)) == ncol(fs)-1)),1]
> name_67 = ss[c(which(rowSums(is.na(ss)) == ncol(ss)-1)),1]
> name_78 = se[c(which(rowSums(is.na(se)) == ncol(se)-1)),1]
> 
> cv_fun <- function(X, y, K=10){
+   N <- nrow(X)
+   folds <- cut(sample(N),breaks=K,labels=FALSE)
+   
+   cv.out <- foreach(k = 1:K, .combine=rbind) %do% {
+     
+     rf <- randomForest(X[(folds != k),], y[(folds != k)],importance = TRUE)
+     imp = sort(rf$importance[,1]/sum(rf$importance[,1]),decreasing = T)[1:20]
+     
+     train_cov = X[(folds != k),c(names(imp))] 
+     train_target = y[(folds != k)]
+     test_cov = X[(folds == k),c(names(imp))]
+     test_target = y[(folds == k)]
+     
+     covs <- array(data = as.matrix(train_cov), dim = c(nrow(train_cov),1,ncol(train_cov)))
+     response <- array(data = as.matrix(train_target), dim = c(nrow(train_cov), 1))
+     covs_test = array(data = as.matrix(test_cov), dim = c(nrow(test_cov),1,ncol(test_cov)))
+     response_test = array(data = as.matrix(test_target), dim = c(nrow(test_cov), 1))
+     
+     
+     input_layer <- layer_input(shape = c(1,ncol(train_cov)))
+     output_layer <- input_layer %>%
+       layer_masking(mask_value = 0) %>%
+       layer_dropout(rate = .5) %>%
+       layer_lstm(units = 64, return_sequences = F, dropout = .5, recurrent_dropout = .5) %>%
+       layer_dropout(rate = .5) %>%
+       layer_dense(units = 1, activation = "linear")
+     
+     model <- keras_model(input_layer, output_layer)
+     model %>% compile(
+       loss = "mse",
+       #metrics = "accuracy",
+       optimizer = optimizer_adam()
+     )
+     
+     
+     history <- model %>% fit(
+       x = covs,
+       y = response,
+       epochs = 200,
+       validation_split = 0.25,
+       verbose = 0,
+       callbacks = list(print_dot_callback)
+     )
+     
+     pred <- model %>% predict(x = covs_test)
+     error_metric <- mean((pred[,1] - response_test)^2)
+     r2_metric <- r2_calc(response_test,pred[,1])
+     it.ob <- c(error_metric, r2_metric)
+     names(it.ob) <- c("mse","r2")
+     
+     it.ob
+     
+     # error_metric[k] <- mean((pred[,1] - response_test)^2) # 
+     # r2_metric[k] = r2_calc(response_test,pred[,1]) #
+   }
+   
+   return(cv.out)
+ }
> 
> 
> data_m = check2 %>% filter((!is.na(outm))&(is.na(outh)))
> data_m = inner_join(data_m, covsRem_noscale, by = 'CAMPUS')
> data_m = data_m %>% filter(variable == "A08")
> data_m = merge(data_m, grdXwalk)
> data_m = dummy_cols(data_m, select_columns = 'GRDSPAN') # 41 levels under GRDSPAN without na in outm
> data_m = subset(data_m,select = -c(GRDTYPE,Type,variable,outm,outh,GRDSPAN,COUNTY)) # dont need to change out to outm becuz
> # out is outm, without na as programmed
> 
> #start from 3 becuz unlike b4, this time out does not have na
> for (i in 3:5145){
+   col = ifelse(is.na(data_m[i]), 1, 0)
+   data_m[paste0("col",i)] = col
+   #df$col2 <- ifelse(is.na(df[2]), 1, 0) # 1 = is NA 
+ }
> 
> data_m$exist34 = ifelse(data_m$CAMPUS %in% name_34,1,0)
> data_m$exist45 = ifelse(data_m$CAMPUS %in% name_45,1,0)
> data_m$exist56 = ifelse(data_m$CAMPUS %in% name_56,1,0)
> data_m$exist67 = ifelse(data_m$CAMPUS %in% name_67,1,0)
> data_m$exist78 = ifelse(data_m$CAMPUS %in% name_78,1,0)
> 
> names(data_m) <- make.names(names(data_m))
> data_m[,3:5145] = scale(data_m[,3:5145])
> # replace na with 0
> data_m[is.na(data_m)] <- 0 # 1394*10321
> 
> 
> X = data_m[,3:ncol(data_m)]
> y = data_m[,2]
> 
> start_time <- Sys.time()
> # 
> middle_zero = cv_fun(X,y,K = 10)
2022-11-17 14:32:14.886274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/usr/local/lib64:/usr/lib/jvm/jre/lib/amd64/server:/sw/pkgs/arc/stacks/gcc/10.3.0/R/4.2.0/lib64/R/lib:/sw/pkgs/coe/o/image-libraries/220318/lib:/sw/pkgs/arc/gcc/10.3.0/lib64:/opt/slurm/lib64::
2022-11-17 14:32:14.887658: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-11-17 14:32:14.887678: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gl3028.arc-ts.umich.edu): /proc/driver/nvidia/version does not exist
2022-11-17 14:32:14.890839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 1s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step

................................................................................
................................................................................
........................................1/5 [=====>........................] - ETA: 0s5/5 [==============================] - 0s 1ms/step
> 
> end_time <- Sys.time()
> end_time - start_time
Time difference of 2.257048 hours
> 
> save(middle_zero,file = 'cv_middle_0.Rdata')
> 
> load('cv_middle_0.Rdata')
> 
> middle_zero
               mse        r2
result.1  66.21918 0.6317042
result.2  61.99755 0.6823381
result.3  32.75230 0.7532798
result.4  55.74370 0.6445402
result.5  45.52198 0.6509527
result.6  67.44510 0.6075138
result.7  49.91458 0.6788605
result.8  59.02309 0.6001561
result.9  87.04124 0.6375469
result.10 61.40341 0.6653114
> cv_error = mean(middle_zero[,1])
> r2 = mean(middle_zero[,2])
> 
> 
> 
> 
> proc.time()
    user   system  elapsed 
8300.039   81.114 8173.385 
